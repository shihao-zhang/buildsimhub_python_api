{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "AUTHOR: Shihao Zhang\n",
    "Date: 9/6/2018\n",
    "\n",
    "What is this script for?\n",
    "This script can convert the sub-hourly data (meaaured data) into hourly data\n",
    "Both input & output data will be in csv format\n",
    "\n",
    "How to use this script?\n",
    "Prepare a csv file. Here is the preparation instruction:\n",
    "1. The first row should indicate the sensor name or header\n",
    "2. The first column must be time stamp\n",
    "\n",
    "Package required:\n",
    "pandas, numpy\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "USER INPUT\n",
    "\"\"\"\n",
    "# list of all sensor spot names, will use the same order for output csv\n",
    "# run the script directly will print those names\n",
    "col_names=['P_L-9-IS_Light','P_L-9-NE_Light', 'P_L-9-NW_Light', 'P_L-9-N_Light','P_L-9-SE_Light', 'P_L-9-SW_Light', 'P_L-9-S_Light', 'P_L-9-W_Light']\n",
    "\n",
    "\n",
    "#Identify downsampling method for each column \n",
    "col_avg=['P_L-9-NE_Light', 'P_L-9-NW_Light', 'P_L-9-N_Light','P_L-9-SE_Light', 'P_L-9-SW_Light', 'P_L-9-S_Light', 'P_L-9-W_Light']\n",
    "col_sum=['P_L-9-IS_Light']\n",
    "\n",
    "path = \"C:/Users/Shihao/Desktop/Shihao_Task/pow_lighting_raw.csv\"\n",
    "save_path = \"C:/Users/Shihao/Desktop/Shihao_Task/pow_lighting_.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'P_L-9-IS_Light': <function sum at 0x00000167F18D1268>, 'P_L-9-NE_Light': <function mean at 0x00000167F18D1C80>, 'P_L-9-NW_Light': <function mean at 0x00000167F18D1C80>, 'P_L-9-N_Light': <function mean at 0x00000167F18D1C80>, 'P_L-9-SE_Light': <function mean at 0x00000167F18D1C80>, 'P_L-9-SW_Light': <function mean at 0x00000167F18D1C80>, 'P_L-9-S_Light': <function mean at 0x00000167F18D1C80>, 'P_L-9-W_Light': <function mean at 0x00000167F18D1C80>}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SCRIPT\n",
    "\"\"\"\n",
    "#create and print a dic of downsampling methods for each column\n",
    "col_methods={}\n",
    "for col in col_names:\n",
    "    if col in col_avg:\n",
    "        col_methods[col]= np.mean\n",
    "    if col in col_sum:\n",
    "        col_methods[col]= np.sum\n",
    "print(col_methods)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['P_L-9-IS_Light', 'P_L-9-NE_Light', 'P_L-9-NW_Light', 'P_L-9-N_Light',\n",
      "       'P_L-9-SE_Light', 'P_L-9-SW_Light', 'P_L-9-S_Light', 'P_L-9-W_Light'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # CSV file should be in ASCII encoding\n",
    "    data = pd.read_csv(path, skiprows=0, header=0,index_col=0,parse_dates=True)\n",
    "    cols = data.columns\n",
    "    print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23041 385\n"
     ]
    }
   ],
   "source": [
    "    # First column is timestamp #data[cols[0]] = pd.to_datetime(data[cols[0]])\n",
    "    # round timestamps to hourly percision as date_hour #data[cols[0]] = data[cols[0]].dt.floor('h')\n",
    "    data_new = data.resample(\"H\").agg(col_methods)\n",
    "    print(len(data),len(data_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # not accepting above hourly data\n",
    "    frequency = len(data)/len(data_new) # records per hour\n",
    "    if frequency > 1:\n",
    "        print(\"Raw data average record:\", 60/frequency,\" per hour\")\n",
    "    else: print(\"Not accepting above hourly data!\")\n",
    "        \n",
    "    #Number of data\n",
    "    #Current resolution (1 min, 15 min etc.)\n",
    "    #Converted resolution (1 hour)\n",
    "    #Missing value encountered at XX time for sensor name: XX\n",
    "    #Completed â€“ time elapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-bb4f928f4f65>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-bb4f928f4f65>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    git add hourly_data_convertor.ipynb\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "!git status\n",
    "git add hourly_data_convertor.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
